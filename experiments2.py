{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "Progress bar"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch.optim as optim\n", "from encodermodels import SimpleConvNetEncoder\n", "from datasets import DataManager\n", "from tqdm.notebook import tqdm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["PyTorch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torch.utils.data as data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "Fetching the device that will be used throughout this notebook"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device(\n", "    \"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n", "print(\"Using device\", device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "DEFINE DATA AND HYPERPARAMETERS"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_config = \"QCD1\"\n", "tran_batch_size = 64\n", "# %%\n", "# DEFINE A DATASET MANAGER\n", "DM = DataManager(data_config=data_config, transform=None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_loader = data.DataLoader(\n", "    DM.train_set, batch_size=tran_batch_size, shuffle=False, drop_last=False)\n", "val_loader = data.DataLoader(\n", "    DM.val_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)\n", "test_loader = data.DataLoader(\n", "    DM.test_bg, batch_size=64, shuffle=False, drop_last=False, num_workers=4)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CLIPLoss(nn.Module):\n", "    def __init__(self, logit_scale=1.):\n", "        super().__init__()\n", "        self.logit_scale = logit_scale\n", "        self.__loss_evol = {'train': [], 'valid': []}\n", "    @property\n", "    def loss_evolution(self):\n", "        return self.__loss_evol\n", "    def item(self):\n", "        return self.item_\n", "    def forward(self, embedding_1, embedding_2, valid=False):\n", "        device = embedding_1.device\n", "        logits_1 = self.logit_scale * embedding_1 @ embedding_2.T\n", "        logits_2 = self.logit_scale * embedding_2 @ embedding_1.T\n", "        num_logits = logits_1.shape[0]\n", "        labels = torch.arange(num_logits, device=device, dtype=torch.long)\n", "        loss = 0.5 * (\n", "            F.cross_entropy(logits_1, labels) +\n", "            F.cross_entropy(logits_2, labels)\n", "        )\n", "        self.__loss_evol['valid' if valid else 'train'].append(loss.item())\n", "        self.item_ = loss.item()\n", "        return loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ExpLoss(nn.Module):\n", "    def __init__(self, logit_scale=1.):\n", "        super().__init__()\n", "    def item(self):\n", "        return self.item_\n", "    def forward(self, embedding_1, embedding_2, valid=False):\n", "        device = embedding_1.device\n", "        loss = ((embedding_1-embedding_2)**2).mean()\n", "        self.item_ = loss.item()\n", "        return loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clip_loss = CLIPLoss()\n", "encoder1 = SimpleConvNetEncoder()\n", "encoder1.to(device)\n", "encoder2 = SimpleConvNetEncoder()\n", "encoder2.to(device)\n", "optimizer = optim.Adam(list(encoder1.parameters()) +\n", "                       list(encoder2.parameters()), lr=0.0001)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for epoch in range(2):  # loop over the dataset multiple times\n", "    running_loss = 0.0\n", "    for i, data in enumerate(train_loader):\n", "        inputs = data[0].reshape(\n", "            data[0].shape[0], data[0].shape[3], data[0].shape[1], data[0].shape[2]).float()\n", "        inputs = inputs.to(device)\n", "        # zero the parameter gradients\n", "        optimizer.zero_grad()\n\n", "        # forward + backward + optimize\n", "        embedding1 = encoder1(inputs)\n", "        embedding2 = encoder2(inputs)\n", "        loss = clip_loss.forward(embedding1, embedding2)\n", "        loss.backward()\n", "        optimizer.step()\n\n", "        # print statistics\n", "        running_loss += clip_loss.item()\n", "        print_T = 20\n", "        if i % print_T == print_T-1:    # print every 2000 mini-batches\n", "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_T:.6f}')\n", "            running_loss = 0.0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}